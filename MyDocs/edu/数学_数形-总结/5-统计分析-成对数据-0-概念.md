## 成对数据（选3）

两个变量有关系，但又没有确切到可由其中的一个精确的决定另一个的程度，这种关系称为**相关关系**

从整体上看，当一个变量的值增加时，另一个变量的相应值也呈现增加的趋势，就称这两个变量**正相关**；.... **负相关**。

如果两个变量的取值呈现正相关或负相关，而且散点落在一条直线附近，就称这两个变量**线性相关**。

如果两个变量具有相关性，但不是线性相关，就称这两个变量**非线形相关**或**曲线相关**。



**样本相关系数**：
$$
r=\frac{1}{n}(x'_1y'_1+x'_2y'_2+...+x'_ny'_n)\\
=\frac{\sum^n_{i=1}(x_i-\overline x)(y_i-\overline y)}{\sqrt{\sum^n_{i=1}(x_i-\overline x)^2}\sqrt{\sum^n_{i=1}(y_i-\overline y)^2}}
$$

- 当$r>0$ 时，称成对样本数据正相关；当$r<0$ 时，称成对样本数据负相关。

- 结合向量知识，知道$-1\le r\le 1$，当$|r|=1$ 时，两个分量满足一种线性关系。$|r|$越接近1，线形相关程度越强；越接近0，越弱。r 的符号反映了相关关系的正负性。

  > r=0 时，只表明没有线性相关关系，但可能有其他相关关系



#### 一元线性回归模型

对于线性相关关系较强的两个变量，可以用一次函数变形来表示两者的关系：$Y=bx+a+e$（1）。其中$Y$ 为因变量或**响应变量**，$x$ 称为自变量或**解释变量**，a 和b 为未知参数（a 为截距参数，b 为斜率参数），e 是$Y$ 与$bx+a$ 之间的随机误差。

若$E(e)=0,D(e)=\sigma^2$，（$\sigma^2$ 是与x 无关的定值），则称（1）式为$Y$ 关于$x$ 的**一元线性回归模型**

##### 最小二乘估计

在具体到样本数据时，模型的参数a,b 需要合适选择，才能使函数“最准确”表达。如下是结论公式：
$$
\hat b=\frac{\sum^n_{i=1}(x_i-\overline x)(y_i-\overline y)}{\sum^n_{i=1}(x_i-\overline x)^2}\\
\hat a=\overline y-\hat b\overline x
$$
将$\hat y=\hat bx+\hat a$ 称为$Y$ 关于$x$ 的**经验回归方程**，也称经验回归函数或经验回归公式，其图形称为经验回归直线。这种求经验回归方程的方法叫做**最小二乘法**，求得的$\hat b,\hat a$ 叫做$b,a$ 的**最小二乘估计**

> 这里的二乘是平方的意思，理论上算“距离”即可，但是平方好计算



对于响应变量$Y$，通过观测得到的数据称为**观测值**，通过经验回归方程得到的$\hat y$ 称为**预测值**，观测值减去预测值称为**残差**。残差是随机误差的估计结果，通过对残差的分析可以判断模型刻画数据的效果，以及判断原始数据中是否存在可疑数据等，这方面工作称为残差分析。

**决定系数**
$$
R^2=1-\frac{\sum^n_{i=1}(y_i-\hat y_i)^2}{\sum^n_{i=1}(y_i-\overline y)^2}
$$
